---
title: "Bikes_01"  
author: "fmarianoc"  
date: "Monday, August 18, 2014"  
output:  
  html_document:  
    keep_md: yes  
    number_sections: yes  
    toc: yes  
  pdf_document: default  
  word_document: default  
---
# Brief report  
As this is a open assignment I prefer to work with something of my interest, then my choice in the Kaggle is the Bike Sharing Demand.  

## Forecast use of a city bikeshare system  

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.  

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.  

## Data files

*__ File Name ________ Available Formats*  
  
- sampleSubmission .csv (139.51 kb)  
- train __________ .csv (633.16 kb)  
- test ___________ .csv (316.27 kb)  

You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.  

## Data fields

- **datetime** - hourly date + timestamp  
- **season** -  1 = spring, 2 = summer, 3 = fall, 4 = winter 
- **holiday** - whether the day is considered a holiday
- **workingday** - whether the day is neither a weekend nor holiday  
- **weather** - 
    1. Clear, Few clouds, Partly cloudy, Partly cloudy  
    2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  
    3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  
    4. Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  
- **temp** - temperature in Celsius  
- **atemp** - "feels like" temperature in Celsius  
- **humidity** - relative humidity  
- **windspeed** - wind speed  
- **casual** - number of non-registered user rentals initiated  
- **registered** - number of registered user rentals initiated  
- **count** - number of total rentals  

## Advice  

This competition was tailored for the machine learning community, and I'm not prepared yet to play with those technics. So, don't expect a good positioning in the leaderboard. The final date is about 8 months from now so, there is some possibility of improvements.  

# My Solution  

I will use some knowledge (against the machine learnig principles).  

## Initial assumptions:  

* There are cycles: days, weeks and seasons.  
* There are singularities: holidays and adverse weather conditions.  
* There are different uses: transportation and fun.  
* There is a window of optimal conditions: climatic conditions within limits.  

## getting data  
### the wd  

```r
setwd("C:\\Users\\Flavio\\Dropbox\\Coursera\\Washington\\IDS\\Kaggle")
```

### the repository  

```r
if(!file.exists("./data")){dir.create("./data")}
```

### the files  

```r
dir()
```

```
##  [1] "bikes_01.docx"      "bikes_01.html"      "bikes_01.md"       
##  [4] "Bikes_01.pdf"       "bikes_01.R"         "Bikes_01.Rmd"      
##  [7] "Bikes_01_files"     "bikes_02.docx"      "bikes_02.R"        
## [10] "bikes_03.docx"      "bikes_03.R"         "bikes_04.R"        
## [13] "classification.png" "data"               "Decision_Trees.pdf"
## [16] "figure"
```

```r
trainFile <- "./data/train.csv"
testFile <- "./data/test.csv"
sampleSubmissionFile <- "./data/sampleSubmission.csv"
```

### notes
I've downloaded then via browser because we need to accept the terms of the competition to get the real data.  
Otherwise, they give us something else.  

```r
## The original commands, commented:
#
# trainUrl <- "http://www.kaggle.com/c/bike-sharing-demand/download/train.csv"
# download.file(trainUrl,destfile=trainFile)
# testUrl <- "http://www.kaggle.com/c/bike-sharing-demand/download/test.csv"
# download.file(testUrl,destfile=testFile)
# sampleSubmissionUrl <- "http://www.kaggle.com/c/bike-sharing-demand/download/sampleSubmission.csv"
# download.file(sampleSubmissionUrl,destfile=sampleSubmissionFile)
#
```

### getting the data

```r
train <- read.csv(file=trainFile)
test <- read.csv(testFile)
sampleSubmission <- read.csv(sampleSubmissionFile)
```

## Adding variables
### first variable, for week cycles

```r
library(data.table)
week_day <- wday(as.Date(train$datetime, format = "%Y-%m-%d %H:%M:%S"))
hist(week_day, breaks=c(0:7), xlab="sun = 0, sat = 7")
```

![plot of chunk var1](figure/var1.png) 

### second variable, the hour of the day

```r
dhour <- as.numeric(format(strptime(train$datetime, format = "%Y-%m-%d %H:%M:%S"), "%H"))
plot(dhour,train$count)
```

![plot of chunk var2](figure/var2.png) 

### third variable, percent of day light
sunrise and sunset at http://www.sunearthtools.com/pt/solar/sunrise-sunset-calendar.php#table  

I got the data for the period and then I've constructed one spreadsheet with 3 columns:  

* **date** %Y-%m-%d  
* **sunrise** %h:%m:%s  
* **sunset** %h:%m:%s  


```r
lightHoursFile <- "./data/Washington_DayLight_2011_2012.csv"
lightHours <- read.csv(lightHoursFile, skip = 3)
lightHours$date <- as.Date(lightHours$date, format="%Y-%m-%d")
#
deltaSeconds <- function(x) {
    seconds <- 3600 * as.numeric(substring(as.character(x), 1, 2)) +
        60 * as.numeric(substring(as.character(x), 4, 5)) +
        as.numeric(substring(as.character(x), 7, 8))
    return(seconds)
}

lightHours$plight <- (deltaSeconds(lightHours$sunset) 
                      - deltaSeconds(lightHours$sunrise)) / 86400
```

#### see the anual cycle - two years plot

```r
plot(lightHours$plight)
```

![plot of chunk twoyears](figure/twoyears.png) 

```r
summary(lightHours$plight)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.394   0.433   0.509   0.508   0.584   0.620
```

## Let's play!

### approach: cart  
- dependent variable:  
-- count  
- independent variables:  
-- season  
-- plight  
-- dhour  
-- week_day  
-- holiday  
-- workingday  
-- weather  
-- atemp  
-- humidity  
-- windspeed  

### preparation  

```r
dth <- data.table(lightHours, key="date")
t1 <- train
t1$date <- as.Date(t1$datetime, format="%Y-%m-%d")
t1$week_day <- week_day
t1$dhour <- dhour
dtt <- data.table(t1, key="date")
dt <- dth[dtt]
str(dt)
```

```
## Classes 'data.table' and 'data.frame':	10886 obs. of  18 variables:
##  $ date      : Date, format: "2011-01-01" "2011-01-01" ...
##  $ sunrise   : Factor w/ 692 levels "05:42:28","05:42:29",..: 670 670 670 670 670 670 670 670 670 670 ...
##  $ sunset    : Factor w/ 708 levels "16:46:09","16:46:10",..: 97 97 97 97 97 97 97 97 97 97 ...
##  $ plight    : num  0.396 0.396 0.396 0.396 0.396 ...
##  $ datetime  : Factor w/ 10886 levels "2011-01-01 00:00:00",..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ season    : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ holiday   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ workingday: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ weather   : int  1 1 1 1 1 2 1 1 1 1 ...
##  $ temp      : num  9.84 9.02 9.02 9.84 9.84 ...
##  $ atemp     : num  14.4 13.6 13.6 14.4 14.4 ...
##  $ humidity  : int  81 80 80 75 75 75 80 86 75 76 ...
##  $ windspeed : num  0 0 0 0 0 ...
##  $ casual    : int  3 8 5 3 0 0 2 1 1 8 ...
##  $ registered: int  13 32 27 10 1 1 0 2 7 6 ...
##  $ count     : int  16 40 32 13 1 1 2 3 8 14 ...
##  $ week_day  : int  7 7 7 7 7 7 7 7 7 7 ...
##  $ dhour     : num  0 1 2 3 4 5 6 7 8 9 ...
##  - attr(*, "sorted")= chr "date"
##  - attr(*, ".internal.selfref")=<externalptr>
```

### train and test of original train  

```r
library(caTools)
set.seed(1108)
split <- sample.split(dt$datetime, SplitRatio = 0.55)
table(split)
```

```
## split
## FALSE  TRUE 
##  4899  5987
```

```r
#
t1train <- subset(dt, split)
t1test <- subset(dt, !split)
```

### simple model  

```r
library(rpart)
library(rpart.plot)
tree <- rpart(count ~ season + plight + dhour + week_day 
              + holiday + workingday + weather + atemp 
              + humidity + windspeed, data=t1train)
prp(tree)
```

![plot of chunk cart](figure/cart.png) 

### prediction  

```r
tree.pred <- as.integer(predict(tree, newdata=t1test))

summary(tree.pred)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      33      33     165     193     302     571
```

```r
summary(t1train$count)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1      43     145     191     281     970
```

### correlation  

```r
cor(tree.pred, t1test$count)
```

```
## [1] 0.8252
```

### now the full train

```r
treeAll <- rpart(count ~ season + plight + dhour + week_day 
                 + holiday + workingday + weather + atemp 
                 + humidity + windspeed, data=dt)
prp(treeAll)
```

![plot of chunk cart_fulltrain](figure/cart_fulltrain.png) 

```r
summary(dt$count)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       1      42     145     192     284     977
```

```r
t2 <- test
t2$date <- as.Date(t2$datetime, format="%Y-%m-%d")
t2$week_day <- wday(as.Date(test$datetime, format = "%Y-%m-%d %H:%M:%S"))
t2$dhour <- as.numeric(format(strptime(test$datetime, format = "%Y-%m-%d %H:%M:%S"), "%H"))
dtt2 <- data.table(t2, key="date")
dt2 <- dth[dtt2]

submit.pred <- as.integer(predict(tree, newdata=dt2))
summary(submit.pred)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      33      33     165     192     226     571
```

```r
write.csv(submit.pred, file="./data/sub140808D.csv")
```

# Evaluation  

# Some Improvement  
